{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\r\n",
    "\r\n",
    "- Extreme Gradient Boosting\r\n",
    "- Objective function made up of training loss and regularization\r\n",
    "    - Training loss measures how predictive our model is on training data (MSE or Logistic loss for regression and classification respectively)\r\n",
    "    - Regularization term controls the complexity of the model, which helps in avoiding overfitting\r\n",
    "- Usually has better performance than gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\r\n",
    "import numpy as np\r\n",
    "import pandas as pd \r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt \r\n",
    "from sklearn import preprocessing\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset('titanic')\r\n",
    "df.dropna(inplace=True)\r\n",
    "X = df[['pclass', 'sex', 'age']].copy()\r\n",
    "le = preprocessing.LabelEncoder()\r\n",
    "X['sex'] = le.fit_transform(df['sex'])\r\n",
    "y = df['survived'].copy()\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\r\n",
    "from sklearn.metrics import accuracy_score, classification_report\r\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\r\n",
    "\r\n",
    "def printScore(clf, X_train, X_test, y_train, y_test, train=True):\r\n",
    "    lb = preprocessing.LabelBinarizer()\r\n",
    "    lb.fit(y_train)\r\n",
    "    if train:\r\n",
    "        res = clf.predict(X_train)\r\n",
    "        print('Train Results:\\n')\r\n",
    "        print('Accuracy: %.2f\\n' % accuracy_score(y_train, res))\r\n",
    "        print('Classification Report: \\n {} \\n'.format(classification_report(y_train, res)))\r\n",
    "        print('Confusion Matrix: \\n {} \\n'.format(confusion_matrix(y_train, res)))\r\n",
    "        print('ROC AUC: {0:.4f}\\n'.format(roc_auc_score(lb.transform(y_train), lb.transform(res))))\r\n",
    "    else:\r\n",
    "        res_test = clf.predict(X_test)\r\n",
    "        print('Test Results:\\n')\r\n",
    "        print('Accuracy: %.2f\\n' % accuracy_score(y_test, res_test))\r\n",
    "        print('Classification Report: \\n {} \\n'.format(classification_report(y_test, res_test)))\r\n",
    "        print('Confusion Matrix: \\n {} \\n'.format(confusion_matrix(y_test, res_test)))\r\n",
    "        print('ROC AUC: {0:.4f}\\n'.format(roc_auc_score(lb.transform(y_test), lb.transform(res_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:34:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.3, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=10000, n_jobs=-1, num_parallel_tree=1,\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(\r\n",
    "    max_depth=5, n_estimators=10000, learning_rate=0.3, n_jobs=-1\r\n",
    ")\r\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results:\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91        55\n",
      "           1       0.94      0.97      0.95       108\n",
      "\n",
      "    accuracy                           0.94       163\n",
      "   macro avg       0.94      0.92      0.93       163\n",
      "weighted avg       0.94      0.94      0.94       163\n",
      " \n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 48   7]\n",
      " [  3 105]] \n",
      "\n",
      "ROC AUC: 0.9225\n",
      "\n",
      "Test Results:\n",
      "\n",
      "Accuracy: 0.74\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.50      0.44         4\n",
      "           1       0.86      0.80      0.83        15\n",
      "\n",
      "    accuracy                           0.74        19\n",
      "   macro avg       0.63      0.65      0.64        19\n",
      "weighted avg       0.76      0.74      0.75        19\n",
      " \n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 2  2]\n",
      " [ 3 12]] \n",
      "\n",
      "ROC AUC: 0.6500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printScore(xgb_clf, X_train, X_test, y_train, y_test)\r\n",
    "printScore(xgb_clf, X_train, X_test, y_train, y_test, train=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c379c6632b839fe8cc95899702fc1eeb76422933665f151db5b483d30b68fa5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}