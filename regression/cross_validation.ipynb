{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\r\n",
    "\r\n",
    "Using the sklearn ```test_train_split``` helper method to partition data into training and test/holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \r\n",
    "import numpy as np \r\n",
    "import matplotlib.pyplot as plt \r\n",
    "import seaborn as sns\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn import datasets \r\n",
    "from sklearn import svm\r\n",
    "\r\n",
    "boston = datasets.load_boston()\r\n",
    "boston.data.shape, boston.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.667431382173115"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.4, random_state=0)\r\n",
    "# 40% of data used for testing\r\n",
    "regression = svm.SVR(kernel='linear', C=1).fit(X_train, y_train)\r\n",
    "regression.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When estimating the value for a model's hyperparameters, such as ```C``` above, it is possible to over/underfit. \r\n",
    "\r\n",
    "To solve this, we can use a validation set between the train and test data to find the optimal value of these hyperparameters. However, this drastically reduces our training data, and the results can depend on the random choice of data for the training and validation data. \r\n",
    "\r\n",
    "We can use Cross Validation (CV) as a solution to this problem. A test set will still be held until the end, but the validation set is no longer needed. In k-fold CV, the training set is split into k smaller sets, with each called a fold. The following is done for all k folds:\r\n",
    "\r\n",
    "- A model is trained using k-1 folds as training data\r\n",
    "- The model is then tested on the remaining data\r\n",
    "\r\n",
    "This performance measure is the average of all the scores across the k-folds used for training. This can be expensive, but does not waste data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing CV Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77285459, 0.72771739, 0.56131914, 0.15056451, 0.08212844])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\r\n",
    "regression = svm.SVR(kernel='linear', C=1)\r\n",
    "scores = cross_val_score(regression, boston.data, boston.target, cv=5)\r\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.46 with error 0.08\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.2f with error %.2f' % (scores.mean(), scores.std() ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the ```cv``` argument is an integer ```cross_val_score``` uses ```KFold``` strategies by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold\r\n",
    "\r\n",
    "Divides all samples in k groups of samples, called folds, or equal sizes (if possible). The prediction function is leanred using k - 1 folds, and the fold left out is for testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of 2-fold CV on dataset with 4 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3] [0 1]\n",
      "[0 1] [2 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\r\n",
    "\r\n",
    "X = ['a', 'b', 'c', 'd']\r\n",
    "kf = KFold(n_splits=2)\r\n",
    "for train, test in kf.split(X):\r\n",
    "    print('%s %s' % (train, test))\r\n",
    "# splits array in two, and uses one as the test and the other as the train, twice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K-Fold\r\n",
    "\r\n",
    "Variation of k-Fold which returns stratified folds, each containing the same percentage of samples of each target class as the complete set. \r\n",
    "\r\n",
    "3-Fold CV with 10 samples from two unbalanced classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 6 7 8 9] [0 1 4 5]\n",
      "[0 1 3 4 5 8 9] [2 6 7]\n",
      "[0 1 2 4 5 6 7] [3 8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\r\n",
    "\r\n",
    "X = np.ones(10)\r\n",
    "y = [0,0,0,0,1,1,1,1,1,1]\r\n",
    "skf = StratifiedKFold(n_splits=3)\r\n",
    "for train,test in skf.split(X,y):\r\n",
    "    print('%s %s' % (train,test))\r\n",
    "# numbers represent indicies. splits in such a way that the 0s within Y are represented in both train and test\r\n",
    "# point of stratified test is to make subgroups representative of data as a whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.391\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "from sklearn import svm\r\n",
    "from sklearn.pipeline import make_pipeline\r\n",
    "# using train/test data created above from boston data\r\n",
    "# pipeline chains together data preprocessing steps, can complete CV in just a few lines\r\n",
    "pipe_svm = make_pipeline(\r\n",
    "    StandardScaler(), PCA(n_components=2), \r\n",
    "    svm.SVR(kernel='linear', C=1)\r\n",
    ")\r\n",
    "pipe_svm.fit(X_train, y_train)\r\n",
    "y_pred = pipe_svm.predict(X_test)\r\n",
    "print('Accuracy: %.3f' % pipe_svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy: 0.428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\r\n",
    "scores = cross_val_score(\r\n",
    "    estimator=pipe_svm, X=X_train, y=y_train, \r\n",
    "    cv=10, n_jobs=-1\r\n",
    ")\r\n",
    "print('CV accuracy: %.3f' % np.mean(scores))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c379c6632b839fe8cc95899702fc1eeb76422933665f151db5b483d30b68fa5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}